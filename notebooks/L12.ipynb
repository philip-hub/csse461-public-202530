{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2849caae-6882-48be-9e5d-53b2aefd4692",
   "metadata": {},
   "source": [
    "# Lecture 12 - Intro to ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8424afae-03bf-49c6-a09a-29556939bf0a",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    "\n",
    "After this class, students will be able to\n",
    "- identify the key elements of a supervised ML system: data, model, parameters, loss function, training loop\n",
    "- define \"training\" in ML\n",
    "- prompt an LLM to generate pytorch ML code\n",
    "- explain what under- and over-fitting are, and the need for train/test splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bc56a3-6511-48f0-9a11-92c8911a39db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm running today's lecture on a GPU server\n",
    "# This line chooses which GPU I'll be running on. Run this line before any other imports. \n",
    "# To change GPUs, restart your kernel and then rerun this cell.\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # Use this GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bccf26-3fa7-4a05-a3c9-ef8958a60cae",
   "metadata": {},
   "source": [
    "### Approach today: zero to ML, a step at a time\n",
    "Many of you have seen ML fundamentals in other classes. You'll know many of the things we're doing today already. We'll begin by designing systems with serious flaws, and we'll fix them as we discover them. Please play along with the story, and don't drop spoilers too soon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053eb7e1-500c-4084-857d-da66a97ccd76",
   "metadata": {},
   "source": [
    "### Approach today: LLMs\n",
    "We're going to try LLM-assisted coding in class today. I have two goals on this:\n",
    "\n",
    "- Demoing how to use AI to assist in developing ML systems\n",
    "- Keeping today's emphasis on ML ideas, rather than on code syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7325255-6168-4365-a364-9a0f17068a7b",
   "metadata": {},
   "source": [
    "## Plan for today:\n",
    "\n",
    "- [ ] Get a dataset - CIFAR10. Explore and visualize.\n",
    "- [ ] Create \"Dataloaders\"\n",
    "- [ ] Prompt an LLM to get a simple model\n",
    "- [ ] Prompt an LLM to learn about our options for loss functions\n",
    "- [ ] Prompt an LLM to get a simple training loop\n",
    "- [ ] Train our model\n",
    "- [ ] Evaluate the performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ea21a6-7ef2-44fd-9f80-3993347eacac",
   "metadata": {},
   "source": [
    "#### Our Dataset: [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "Why?\n",
    "\n",
    "- it's a vision dataset\n",
    "- the vision problem (image classification) is relatively straightforward\n",
    "- it's small enough we can do training runs live in class\n",
    "\n",
    "pyTorch comes with several built-in datasets, ranging from quite small to very large. Let's use pytorch to load this dataset next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00524c64-cbe3-4105-a62e-5d6200551df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell: train a model to do image classification on CIFAR10\n",
    "# demo LLM prompting\n",
    "# create new cells as needed\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9db516-978a-48a5-b27a-e03a2412e984",
   "metadata": {},
   "source": [
    "#### Summary: What does it mean to train a model?\n",
    "\n",
    "A model is a programmatically-defined function whose outputs depend on two things:\n",
    "\n",
    "- An input (think, an image to process)\n",
    "- Parameters (the coefficients in the huge list of equations that a model uses internally to process data)\n",
    "\n",
    "Training is optimization: we're searching for a special set of parameters that cause the model to mostly give the right answers for most inputs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "004de0f9-c92c-4e59-8441-54a021492939",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"https://imgs.xkcd.com/comics/machine_learning_2x.png\" width=\"360\"/>\n",
    "</div>\n",
    "\n",
    "Link: [xkcd 1838](https://xkcd.com/1838)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2b4f2c-a06d-4ae7-ad7c-39da242d2cd8",
   "metadata": {},
   "source": [
    "#### Summary: Elements of Training in PyTorch\n",
    "\n",
    "We used an LLM to generate most of this code. Any working solution should have all of these pieces:\n",
    "\n",
    "- Dealing with data:\n",
    "  - `torch.utils.data.Dataset` : a list of data and labels\n",
    "  - `torch.utils.data.random_split` : a function that randomly splits your data into train and test sets, if your dataset doesn't come with a split given to you\n",
    "  - `torch.utils.data.DataLoader` : a wrapper around a `Dataset` that generates random \"batches\" as needed\n",
    "- Setting up a model:\n",
    "  - `torch.nn.Module` : code that says how your model processes input and creates output\n",
    "- A \"training loop\" that does model training. (outer loop: epochs. inner loop: batches.)\n",
    "  - `torch.nn.Loss` : a small function that decides how far the model's output is from the right answer\n",
    "  - `torch.nn.Optimizer` : a choice of an algorithm that searches for a set of Parameters that work\n",
    "\n",
    "**Vocab**: an *epoch* is one pass through the training dataset. A model that has been trained for one epoch has seen each image in the training dataset exactly once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c33aa1a-80bd-47f2-9987-899278247a36",
   "metadata": {},
   "source": [
    "## Theory topic: Underfitting and Overfitting\n",
    "\n",
    "Underfitting and overfitting are universally useful concepts in ML, but it's hard to directly visualize these in the context of neural networks. Neural nets are large, complex, and high dimensional. So we're going to play with a toy problem that's easy to visualize.\n",
    "\n",
    "Our demo problem:\n",
    "- Input: a single real number\n",
    "- Output: a single real number\n",
    "- Fake data: a simple cubic function + Gaussian noise\n",
    "- Models: polynomials of degree k (we'll try various values of k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258e4912-492b-40f2-8647-7227d4a6b586",
   "metadata": {},
   "source": [
    "#### Problem setup: random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b368a715-b997-4b01-a1d7-6d2d31fcb969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the under/over-fitting demo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf6ea7b-a038-4a0d-851d-0c8d977e593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed a random number generator.\n",
    "# This is overkill, but I finally got around to looking \n",
    "# up the official \"right\" way to do it.\n",
    "from numpy.random import MT19937\n",
    "from numpy.random import RandomState, SeedSequence\n",
    "rs = RandomState(MT19937(SeedSequence(123)))\n",
    "\n",
    "\n",
    "###################\n",
    "# data parameters #\n",
    "###################\n",
    "# (are fancy comment boxes like this tacky?)\n",
    "n_train = 30\n",
    "n_test = 50\n",
    "noise_sd = 0.008\n",
    "\n",
    "# The numpy.polynomial package has a really convenient function \n",
    "# for constructing polynomials from a list of roots.\n",
    "# But it uses the opposite storage convention from polyfit and polyval.\n",
    "true_model = np.polynomial.polynomial.polyfromroots([0.15, 0.35, .45, 0.9])\n",
    "true_model = true_model[::-1] # reverse the list\n",
    "\n",
    "# make the x coords of the data\n",
    "x_train = np.sort(rs.uniform(0, 1, n_train))\n",
    "x_test = np.sort(rs.uniform(0, 1, n_test))\n",
    "\n",
    "# make the y coords of the data\n",
    "y_train = np.polyval(true_model, x_train) + rs.normal(0, noise_sd, n_train)\n",
    "y_test = np.polyval(true_model, x_test) + rs.normal(0, noise_sd, n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40477de-5ef8-4303-9fc0-116bdb4f0627",
   "metadata": {},
   "source": [
    "#### Check our work:\n",
    "plot the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b73eb-0ac4-4013-8549-d23f39c670dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the model and the data\n",
    "plt.plot(x_train, y_train, '.b', label='train set')\n",
    "plt.plot(x_test, y_test, '.r', label='test set')\n",
    "\n",
    "x_model = np.linspace(0, 1, 200)\n",
    "y_model = np.polyval(true_model, x_model)\n",
    "plt.plot(x_model, y_model, '-k', label='true function')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e98f2f-4a1c-4d26-94ae-0310a6389d24",
   "metadata": {},
   "source": [
    "#### Experiment: which model fits best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b019f492-5327-49f9-abef-2150d03e8403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(degree, ax):\n",
    "    \n",
    "    model = np.polyfit(x_train, y_train, degree)\n",
    "    \n",
    "    # Plot the model and the data\n",
    "    ax.plot(x_train, y_train, '.b', label='train set')\n",
    "    #ax.plot(x_test, y_test, '.r', label='test set')\n",
    "\n",
    "    x_model = np.linspace(0, 1, 200)\n",
    "    y_model = np.polyval(model, x_model)\n",
    "    ax.plot(x_model, y_model, '-k', label=f'degree {degree} model')\n",
    "\n",
    "    train_errors = y_train - np.polyval(model, x_train)\n",
    "    test_errors = y_test - np.polyval(model, x_test)\n",
    "    train_mae = np.average(np.absolute(train_errors))\n",
    "    test_mae = np.average(np.absolute(test_errors))\n",
    "\n",
    "    perf_text = 'train mae: {:.2e}\\ntest mae: {:.2e}'.format(train_mae, test_mae)\n",
    "    ax.text(0.5, 0.95, perf_text,\n",
    "            verticalalignment='top', horizontalalignment='center',\n",
    "            transform=ax.transAxes,\n",
    "            color='black', fontsize=10)\n",
    "\n",
    "    deg_text = f'degree {degree} model'\n",
    "    ax.text(0.02, 0.02, deg_text,\n",
    "            verticalalignment='bottom', horizontalalignment='left',\n",
    "            transform=ax.transAxes,\n",
    "            color='black', fontsize=10)\n",
    "\n",
    "    ax.set_ylim([-0.05, 0.05])\n",
    "    ax.get_xaxis().set_ticks([])\n",
    "    ax.get_yaxis().set_ticks([])\n",
    "    #ax.set_xlabel('x')\n",
    "    #ax.set_ylabel('y')\n",
    "    # ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c79a963-a2f2-4316-85a0-9cf4688fedbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 5\n",
    "ncols = 4\n",
    "nplots = ncols * nrows\n",
    "fig, axarr = plt.subplots(nrows, ncols, sharex=True, figsize=(16,12))\n",
    "for degree in range(0, nplots):\n",
    "    experiment(degree, axarr[degree // ncols][degree % ncols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4007fcac-772f-4dd7-8217-85d01f6533e6",
   "metadata": {},
   "source": [
    "#### Experiment: Peformance vs Model Complexity\n",
    "Redo the experiment above. But don't plot the individual models. Just plot the performance of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d8532-2c95-45f9-9541-2d61fe0320f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "degrees = np.arange(0, 12)\n",
    "train_mae = []\n",
    "test_mae = []\n",
    "\n",
    "for degree in degrees:\n",
    "    model = np.polyfit(x_train, y_train, degree)\n",
    "    \n",
    "    train_errors = y_train - np.polyval(model, x_train)\n",
    "    test_errors = y_test - np.polyval(model, x_test)\n",
    "    train_mae.append(np.average(np.absolute(train_errors)))\n",
    "    test_mae.append(np.average(np.absolute(test_errors)))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5,8))\n",
    "ax.plot(degrees, train_mae, '-b', label='Train set')\n",
    "ax.plot(degrees, test_mae, '-r', label='Test set')\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.grid('on')\n",
    "ax.set_xlabel('Model complexity (degree)')\n",
    "ax.set_ylabel('Performance (MAE - mean absolute error)')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaf8a04-f8ca-45bc-b3ee-62de907bbb51",
   "metadata": {},
   "source": [
    "### Summary: Model Complexity\n",
    "\n",
    "Bigger models have more parameters. They can fit more things than simple models. Training performance pretty much always improves with higher complexity, but that isn't real! When we check against the test set we see that there's a sweet spot for the right complexity, and anything more than that makes us do worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f02b237-dfd0-4f2a-ba31-8732fed875dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csse461",
   "language": "python",
   "name": "csse461"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
